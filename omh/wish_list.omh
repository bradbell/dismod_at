$Id:$
# SPDX-License-Identifier: AGPL-3.0-or-later
# SPDX-FileCopyrightText: University of Washington <https://www.washington.edu>
# SPDX-FileContributor: 2014-22 Bradley M. Bell
# ----------------------------------------------------------------------------
$begin wish_list$$
$spell
   cppad
   args
   checkpointing
   cpp
   cv
   dage
   def
   dev
   dismod
   dtime
   eigen
   integrands
   ipopt
   kwargs
   mu
   optimizer
   pos
   sim
   std
   var
$$

$section Dismod_at Wish List$$

$head Speed$$
The CppADCodeGen package compiles CppAD code.
While the compilation takes time, the resulting derivative evaluations
are much faster; see
$href%https://coin-or.github.io/CppAD/doc/speed_cppadcg.htm%speed-cppadcg%$$.
Perhaps it is possible to make certain calculations; e.g.,
the ODE solution an CppAD atomic function that is evaluated using
CppADCodeGen code.

$head Bound Constraints$$
$list number$$
Currently the user must convert active bound constraints to equality
constraints to get asymptotic statistics for the fixed effects,
because the Hessian of the objective is often not positive definite.
Automatically detect when these bound constraints
are active at the solution and treat the corresponding variables as
equality constraints during the asymptotic statistics calculation.
$lnext
Document how the bounds affect the priors and posterior distributions
during the fit, simulate, and sample commands.
Note that there is some discussion of bounds in the
$cref/simulating priors/wish_list/Simulating Priors/$$ wish list item below.
$lend

$head Laplace Random Effect$$
The marginal likelihood for Laplace random effects is smooth,
because the model for the data is smooth w.r.t. the random effects.
Hence, it is possible to extend dismod_at to include Laplace random effect.
In addition, the random effects in dismod_at are not correlated.
It follows that, the integral of Gaussian random effects
(Laplace random effects) can be evaluated using the error function
(exponential function).
Thus, we could include bounds on the random effect.

$head Immunity$$
It would be possible to include an immunity state $latex I$$ and have
$latex \rho$$ the rate at which one gets curred from the disease, and does
not get it again. There would be a switch that one chooses to say that onces
you are curred you become immune. This would require changing
the definition of some of the integrands; e.g., prevalence would be
$latex C / (S + C + I)$$. It would also require changing the ODE, but in
a way that should be faster because there is no feedback.

$head Simulating Priors$$
The code for simulating values for the prior distribution
$cref/prior_sim_value/prior_sim_table/prior_sim_value/$$
currently truncates the simulated values to be within the
lower and lower limits for the distribution.
Note that constraining an optimizer to be between lower
and upper limits corresponds to truncated distribution.
The mean for a truncated distribution need not lie between
the lower and upper limits.
We should remove the truncation in the simulated prior values
and we should remove the restriction that the prior table
$cref/mean/prior_table/mean/$$ needs to be between the
lower and upper limits.
This will require projecting onto the lower and upper limits
when the prior mean is used in the $cref start_var_table$$ or
$cref scale_var_table$$.

$head Multi-Threading$$
On a shared-memory system,
it should be possible to split the data into subsets
and evaluate the corresponding likelihood terms
using a different thread for each subset.
The function, and derivative values, corresponding to
each thread would then be summed to get the value corresponding
to the entire likelihood.
This should be done for the initialization
as well as for the function and derivative evaluation during optimization.
The execution time for problems with large amounts of data
should be divided by a number close to the number of cores
available on the system.

$head User Examples$$
The $cref user_example$$ examples below
$cref/examples with explanation/user_example/Examples With Explanation/$$
have a discussion at the top of each example.
Add a discussion for the other the user examples.

$head meas_std$$
Currently the data table
$cref/meas_std/data_table/meas_std/$$
must be specified (except for uniform density).
Perhaps we should allow for this standard deviation to be
$code null$$ in the case when the corresponding
$cref/meas_value/data_table/meas_value/$$ must not be zero
and the $cref/minimum_meas_cv/integrand_table/minimum_meas_cv/$$
would be used to determine the measurement accuracy.

$head Lagrange Multipliers$$
Change the Lagrange multipliers
$cref/lagrange_dage/fit_var_table/lagrange_dage/$$ (dtime) in the
fit_var table to be null when there is no corresponding age (time) different;
i.e., at the maximum age (time).
(Currently these Lagrange multipliers are zero.)

$head Censored Laplace$$
The censored density formula for a Gaussian
$cref/G(y,mu,delta,c)
   /censor_density
   /Gaussian
   /Censored Density, G(y,mu,delta,c)
/$$
is correct even if $latex c > \mu$$.
On the other hand, the formula for the Laplace case
$cref/L(y,mu,delta,c)
   /censor_density
   /Laplace
   /Censored Density, L(y,mu,delta,c)
/$$
requires $latex c \leq \mu$$.
The Laplace case can be extended using the fact that it is symmetric,
integrating from $latex \mu$$ to $latex c$$,
using absolute values for the integration limits,
and the Sign function.
This will result in a non-smooth the optimization problem.
Perhaps the problem can be reformulated with auxillary variables
to be a smooth problem ?

$head create_database$$
Make a version of $cref create_database$$ that uses
keyword arguments and replaces the ones that are not present by
default values. This could be done using the prototype
$codei%
   def create_database(*%args%, **%kwargs%) :
%$$
where $icode args$$ are the positional arguments and
$icode kwargs$$ are the keyword arguments.
This would enable backward compatibility.

$head ODE Solution$$

$subhead Prevalence ODE$$
If $latex S$$ and $latex C$$ satisfy the dismod_at
$cref/ordinary differential equation
   /avg_integrand/Ordinary Differential Equation
/$$ then prevalence $latex P = C / (S + C)$$ satisfies
$latex \[
   P' = \iota  [ 1 - P ] - \rho P - \chi  [ 1 - P] P
\] $$
We can therefore solve for prevalence without other cause mortality
$latex \omega$$ or all cause mortality $latex \omega + \chi P$$.
$list number$$
The ODE for $latex P$$ is non-linear,
while the ODE is $latex (S, C)$$ is linear.
$lnext
All of the current integrands, except for
$cref/susceptible/avg_integrand/Integrand, I_i(a,t)/susceptible/$$ and
$cref/withC/avg_integrand/Integrand, I_i(a,t)/withC/$$
can be computed from $latex P$$ (given that the rates are inputs to the ODE).
$lnext
If we know all cause mortality $latex \alpha = \omega + \chi P$$,
once we have solved for $latex P$$,
we can compute $latex \omega = \alpha - \chi P$$.
Furthermore
$latex \[
   (S + C)' = - \alpha (S + C)
\] $$
So we can also compute $latex S + C$$, and
$latex C = P (S + C)$$,
$lnext
Given the original ODE, we know that the true solution for
$latex S$$, must be positive, and $latex C$$, $latex P$$ must be
non-negative.
Negative values for these quantities will correspond to
numerical precision errors in the solution of the ODE.
$lnext
One advantage of this approach,
over the current approach of solving the ODE in $latex (S, C)$$,
is that the solution is stable as $latex S + C \rightarrow 0$$.
(The current approach computes $latex P = C / (S + C)$$.
$lend

$subhead Large Excess Mortality$$
If case where $icode rate_case$$ is
$cref/iota_pos_rho_zero/option_table/rate_case/iota_pos_rho_zero/$$
corresponds to
$code dev::eigen_ode2::Method::Case Three$$ in the ODE solver.
If excess mortality $latex \chi$$ is unreasonably large,
this can result in exponential overflow and infinity or nan.
It is possible to redo the calculations in case three to properly
handle this condition.

$subhead rate_case$$
It is now possible to use conditional expressions in the ODE solution
(CppAD this will now work properly these conditionals
and two levels of AD and revere mode).
This change would remove the need for the
$cref/rate_case/option_table/rate_case/$$ option.
Note that this will also work with checkpointing.

$head Command Diagrams$$
It would be good to give a data flow diagram for each command
that corresponds to its
$cref/extra inputs tables/data_flow/Command Extra Input Tables/$$ and
$cref/output tables/data_flow/Command Output Tables/$$.

$head Real World Example$$
It would be good to include a real world example.
Since this is an open source program, we would need a data set
that could be made distributed freely without any restriction on its use.

$head Random Starting Point$$
Have an option to start at a random point from the prior for the fixed effects
(instead of the mean of the fixed effects).
This would better detect local minima and represent solution uncertainty.

$head Windows Install$$
Make and test a set of Windows install instructions for $code dismod_at$$.

$end
